# ğŸ“Š AnÃ¡lise de Dados ANS - ETL e VisualizaÃ§Ã£o

Este projeto consiste em uma soluÃ§Ã£o completa de **Engenharia de Dados (ETL)** e **Desenvolvimento Web** para anÃ¡lise das despesas das operadoras de planos de saÃºde, utilizando dados pÃºblicos da **ANS (AgÃªncia Nacional de SaÃºde Suplementar)**.

O sistema automatiza a extraÃ§Ã£o de arquivos zipados complexos, trata inconsistÃªncias de codificaÃ§Ã£o (UTF-8/Latin1), consolida as informaÃ§Ãµes em um banco de dados MySQL e apresenta os resultados em uma interface web interativa.

## ğŸš€ Funcionalidades Principais

### 1. Processamento de Dados (ETL)
- **ExtraÃ§Ã£o AutomÃ¡tica:** O script `processador.py` varre a pasta de downloads e identifica arquivos `.zip` da ANS.
- **Tratamento de Encoding Inteligente:** Resolve o problema de arquivos mistos (UTF-8 e Latin1/CP1252) que quebram a acentuaÃ§Ã£o (ex: "ASSISTÃŠNCIA" vs "ASSISTÃƒNCIA").
- **Cruzamento de Dados:** Enriquece as tabelas financeiras cruzando com o cadastro oficial das operadoras (RazÃ£o Social, CNPJ, UF) via API/CSV da ANS.
- **Limpeza de Dados:** Remove linhas Ã³rfÃ£s (sem registro ANS vÃ¡lido) e padroniza campos nulos.

### 2. Banco de Dados
- **InserÃ§Ã£o Segura:** O script `popular_banco.py` utiliza Python para inserir dados no MySQL, contornando limitaÃ§Ãµes de importaÃ§Ã£o do Workbench e garantindo a integridade dos caracteres especiais.
- **Modelagem Relacional:** Estrutura otimizada para consultas rÃ¡pidas por operadora.

### 3. Interface Web (Frontend)
- **Dashboard Interativo:** VisualizaÃ§Ã£o limpa dos dados em `index.html`.
- **Busca e Filtros:** Pesquisa dinÃ¢mica de operadoras.
- **Tecnologias:** Desenvolvido com Vue.js (CDN) para reatividade sem necessidade de build complexo.

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **Linguagem:** Python 3.12+
- **Bibliotecas Python:**
  - `pandas` (ManipulaÃ§Ã£o de dados massivos)
  - `mysql-connector-python` (ConexÃ£o com Banco de Dados)
  - `requests` (Download de dados cadastrais)
  - `python-dotenv` (GestÃ£o segura de credenciais)
- **Banco de Dados:** MySQL
- **Frontend:** HTML5, CSS3, Vue.js

---

## âš–ï¸ DecisÃµes TÃ©cnicas e Trade-offs

Conforme solicitado nas instruÃ§Ãµes, abaixo estÃ£o documentadas as principais decisÃµes de arquitetura e implementaÃ§Ã£o, bem como as justificativas para cada escolha.

### 1. ETL e Processamento de Dados

#### **EstratÃ©gia de Processamento: Streaming/Incremental vs. In-Memory**
* **DecisÃ£o:** Processamento incremental (arquivo a arquivo) com leitura otimizada via Pandas.
* **Justificativa:** Embora o volume de dados atual (3 trimestres) pudesse caber na memÃ³ria, optei por uma abordagem que processa cada arquivo ZIP individualmente. Isso garante que a soluÃ§Ã£o seja **escalÃ¡vel** (Resiliente). [cite_start]Se precisÃ¡ssemos processar 10 anos de histÃ³rico, a abordagem *In-Memory* travaria por falta de RAM, enquanto a abordagem incremental continuaria funcionando com consumo de memÃ³ria constante[cite: 38, 39].

#### **Tratamento de InconsistÃªncias de Encoding (O Desafio UTF-8 vs Latin1)**
* **Problema:** Identificou-se que a ANS mistura arquivos em UTF-8 e Latin1 (CP1252), alÃ©m de conter bytes invÃ¡lidos (`0x8d`) em alguns arquivos de cadastro.
* **DecisÃ£o:** ImplementaÃ§Ã£o de um `TextIOWrapper` com estratÃ©gia `errors='replace'`.
* **Justificativa:** ForÃ§ar Latin1 corrompia caracteres em arquivos UTF-8 (ex: "ASSISTÃŠNCIA" virava "ASSISTÃƒNCIA"). Tentar apenas UTF-8 quebrava o script nos arquivos antigos. A soluÃ§Ã£o hÃ­brida adotada forÃ§a a leitura em UTF-8 para preservar a acentuaÃ§Ã£o correta e substitui bytes corrompidos isolados em vez de abortar o processo. [cite_start]Isso prioriza a **disponibilidade** e **integridade legÃ­vel** dos dados[cite: 36, 50].

#### **Tratamento de Dados Ã“rfÃ£os (Integridade Referencial)**
* **DecisÃ£o:** Remover linhas de despesas onde o `REG_ANS` nÃ£o pÃ´de ser identificado/convertido para numÃ©rico.
* **Justificativa:** O Registro ANS Ã© a chave primÃ¡ria da operadora. Permitir dados sem essa chave violaria a integridade do banco de dados e geraria relatÃ³rios inconsistentes. [cite_start]Dados sem identificaÃ§Ã£o de origem nÃ£o tÃªm valor analÃ­tico confiÃ¡vel neste contexto[cite: 50, 64].

---

### 2. Banco de Dados e Modelagem

#### **NormalizaÃ§Ã£o: Tabela Ãšnica vs. Tabelas Separadas**
* **DecisÃ£o:** OpÃ§Ã£o B - Tabelas Normalizadas (`operadoras` e `despesas` separadas).
* **Justificativa:**
    1.  **RedundÃ¢ncia:** Repetir a `RazaoSocial`, `CNPJ` e `UF` para cada lanÃ§amento financeiro (milhares de linhas) desperdiÃ§aria armazenamento e I/O.
    2.  **Manutenibilidade:** Se uma operadora mudar de RazÃ£o Social, na tabela normalizada atualizamos apenas 1 linha. Na desnormalizada, terÃ­amos que atualizar milhares de registros.
    3.  [cite_start]**Performance:** Queries de agregaÃ§Ã£o (somas, mÃ©dias) sÃ£o mais rÃ¡pidas em tabelas de fatos (`despesas`) mais "magras" (apenas IDs e valores)[cite: 109, 110].

#### **Tipos de Dados MonetÃ¡rios**
* **DecisÃ£o:** Uso de `DECIMAL` (ou equivalente no Pandas antes da inserÃ§Ã£o) em vez de `FLOAT`.
* **Justificativa:** Dados financeiros exigem precisÃ£o exata. O tipo `FLOAT` utiliza ponto flutuante binÃ¡rio, o que pode acarretar erros de arredondamento em somas grandes (o clÃ¡ssico problema do `0.1 + 0.2 != 0.3`). [cite_start]Para contabilidade, precisÃ£o decimal Ã© obrigatÃ³ria[cite: 114, 116].

#### **InserÃ§Ã£o de Dados: Script Python vs. LOAD DATA INFILE**
* **DecisÃ£o:** InserÃ§Ã£o via script Python (`mysql-connector`) em lotes.
* **Justificativa:** O comando nativo `LOAD DATA` do SQL Ã© mais rÃ¡pido, porÃ©m extremamente sensÃ­vel a configuraÃ§Ãµes de servidor e encoding (especialmente em Windows). [cite_start]O script Python atua como uma camada de seguranÃ§a, sanitizando dados (convertendo "NÃ£o Encontrado" para `NULL`) e garantindo que o encoding `utf8mb4` seja respeitado independente do sistema operacional onde o teste for corrigido[cite: 118, 119].

---

### 3. API e Backend (SugestÃ£o - Ajuste conforme o que vocÃª fez)

#### **Framework: FastAPI vs. Flask**
* **DecisÃ£o:** FastAPI.
* [cite_start]**Justificativa (Se FastAPI):** Alta performance (assÃ­ncrono), validaÃ§Ã£o de dados automÃ¡tica com Pydantic e geraÃ§Ã£o automÃ¡tica de documentaÃ§Ã£o (Swagger UI), o que facilita o teste das rotas conforme exigido[cite: 147, 150].


#### **EstratÃ©gia de PaginaÃ§Ã£o**
* **DecisÃ£o:** Offset-based (`LIMIT` / `OFFSET`).
* **Justificativa:** O volume de operadoras (cerca de 700-1000 ativas) nÃ£o justifica a complexidade de *Cursor-based pagination*. [cite_start]O *Offset* Ã© simples de implementar, intuitivo para o Frontend e performÃ¡tico o suficiente para este volume de dados[cite: 152, 155].

---

### 4. Frontend (Vue.js)

#### **Busca e Filtros: Server-side vs. Client-side**
* **DecisÃ£o:** Busca no Servidor (Server-side).
* **Justificativa:** Embora o dataset atual seja pequeno, em um cenÃ¡rio real de "Big Data" da ANS, carregar todos os registros para o navegador do cliente causaria lentidÃ£o e alto consumo de memÃ³ria. [cite_start]A busca no servidor Ã© a soluÃ§Ã£o correta pensando em escalabilidade e performance do dispositivo do usuÃ¡rio[cite: 175, 178].

#### **Gerenciamento de Estado**
* **DecisÃ£o:** Props e Events simples (ou Composition API).
* **Justificativa:** A aplicaÃ§Ã£o possui baixa complexidade de compartilhamento de estado (basicamente listagem -> detalhes). [cite_start]Introduzir uma lib complexa como Pinia ou Vuex adicionaria "overhead" desnecessÃ¡rio e violaria o princÃ­pio KISS (Keep It Simple) valorizado no teste[cite: 181, 206].

---

## âš™ï¸ PrÃ©-requisitos

Antes de comeÃ§ar, vocÃª precisa ter instalado:
- [Python 3.x](https://www.python.org/downloads/)
- [MySQL Server](https://dev.mysql.com/downloads/mysql/)
- Git

---

## ğŸ“¦ Como rodar o projeto

### Passo 1: Clone o repositÃ³rio
```bash
git clone [https://github.com/Rafael-G-Souza/analise-dados-ans.git](https://github.com/Rafael-G-Souza/analise-dados-ans.git)
cd analise-dados-ans
Passo 2: Configure o Ambiente
Crie um ambiente virtual (recomendado):

Bash
python -m venv .venv
source .venv/bin/activate  # No Windows: .venv\Scripts\activate
Instale as dependÃªncias:

Bash
pip install -r requirements.txt
Configure as variÃ¡veis de ambiente:

Crie um arquivo chamado .env na raiz do projeto.

Adicione sua senha do MySQL (nÃ£o use aspas):

Snippet de cÃ³digo
DB_PASSWORD=sua_senha_aqui
Passo 3: Configure o Banco de Dados
Execute o script SQL (disponÃ­vel na pasta sql/ ou via Workbench) para criar a tabela:

SQL
CREATE DATABASE IF NOT EXISTS ans_analytics;
USE ans_analytics;

CREATE TABLE IF NOT EXISTS operadoras (
    reg_ans INT PRIMARY KEY,
    cnpj VARCHAR(20),
    razao_social VARCHAR(255),
    modalidade VARCHAR(100),
    uf CHAR(2)
) CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;
Passo 4: Execute o Pipeline
Processe os arquivos: (Certifique-se de ter os ZIPs na pasta downloads ou configure o script para baixar)

Bash
python processador.py
Isso irÃ¡ gerar o arquivo data/processed/consolidado_despesas.csv.

Popule o Banco de Dados:

Bash
python popular_banco.py
Isso irÃ¡ limpar a tabela antiga e inserir os novos dados processados.

Acesse a Interface:

Abra o arquivo index.html diretamente no seu navegador.

ğŸ“‚ Estrutura do Projeto
Plaintext
analise-dados-ans/
â”‚
â”œâ”€â”€ .gitignore          # Arquivos ignorados pelo Git
â”œâ”€â”€ .env                # Credenciais (NÃƒO COMMITAR)
â”œâ”€â”€ requirements.txt    # DependÃªncias do Python
â”œâ”€â”€ README.md           # DocumentaÃ§Ã£o do projeto
â”‚
â”œâ”€â”€ processador.py      # Script principal de ETL
â”œâ”€â”€ popular_banco.py    # Script de carga no MySQL
â”œâ”€â”€ index.html          # Interface Frontend
â”‚
â”œâ”€â”€ data/               # Armazena os CSVs processados
â”‚   â””â”€â”€ processed/
â”‚
â””â”€â”€ frontend/           # Scripts e estilos adicionais
    â”œâ”€â”€ script.js
    â””â”€â”€ styles.css
ğŸ‘¨â€ğŸ’» Autor
Rafael G. Souza

Este projeto foi desenvolvido como parte de um teste tÃ©cnico para avaliaÃ§Ã£o de competÃªncias em Engenharia de Dados e Desenvolvimento Full Stack.